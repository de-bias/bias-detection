---
title: "measure-bias"
format: html
editor: visual
---

# Import libraries 

```{r}
library(dplyr)
library(sf)
library(ggplot2)
library(tmap)
library(viridis)
library(spdep)
library(sysfonts)
library(showtextdb)
library(classInt)
library(scales)
library(forcats)
library(spgwr)
```

# Set themes

```{r}
#| include = FALSE
source("./style/data-visualisation_theme.R")
```

# Set parameters

```{r}
# Set digital trace data source: twitter, fb_tts_census_week, fb_tts_census_month, fb_stt_census_week, fb_stt_census_month
dfd <- "fb_stt_census_month"

# Set weights scheme: queen, fbw, knn, db
w_scheme <- 'db'
```

# Data import

## Census and boundaries

```{r}
wd <- "/Volumes/rdm04/DEBIAS"
wd_local <- "/Users/carmen/Documents/github/de-bias"
```

```{r}
df_pop_census <- read.csv(paste0(wd, "/data/inputs/census/census2021-ts/census2021-ts001/census2021-ts001-ltla.csv")) %>% select(date, geography, geography.code, Residence.type..Total..measures..Value) %>% rename("code" = "geography.code", "name" = "geography", "pop" = "Residence.type..Total..measures..Value")

df_boundaries <- st_read(paste0(wd, "/data/inputs/geographies/boundaries/LAD_Dec_2021_GB_BFC_2022.gpkg")) %>% select(LAD21CD, SHAPE) %>% rename("code" = "LAD21CD")

df_boundaries_up <- st_read(paste0(wd, "/data/inputs/geographies/boundaries/RGN_Dec_2021_EN_BFC_2022.gpkg")) %>% st_simplify(preserveTopology = FALSE, dTolerance = 1000)

df_boundaries_hex <- st_read(paste0(wd, "/data/inputs/geographies/hexboundaries/uk-local-authority-districts-2021.geojson")) %>% st_transform(st_crs(df_boundaries_up)) %>% rename("code" = "id")
```




## Digital trace data

This first line defines the data source to be analysed. We have five options:

-   `twitter`

-   `fb_tts_census_week`

-   `fb_tts_census_month`

-   `fb_stt_census_week`

-   `fb_stt_census_month`


```{r}
if (dfd == "twitter") {
  df_pop_dfd <- read.csv(paste0(wd, "/data/inputs/twitter/monthly/active_population.csv")) %>% 
    filter(time == "2021-03")
  } else if (dfd == "fb_tts_census_week") {
  df_pop_dfd <- read.csv(paste0(wd, "/data/inputs/fb/census-week/tts/active_population.csv")) %>% 
  rename("name" = "LAD21NM")
  } else if (dfd == "fb_tts_census_month") {
  df_pop_dfd <- read.csv(paste0(wd, "/data/inputs/fb/census-month/tts/active_population.csv")) %>% 
  rename("name" = "LAD21NM")
  } else if (dfd == "fb_stt_census_week") {
  df_pop_dfd <- read.csv(paste0(wd, "/data/inputs/fb/census-week/stt/active_population.csv")) %>% 
  rename("name" = "LAD21NM")
  } else if (dfd == "fb_stt_census_month") {
  df_pop_dfd <- read.csv(paste0(wd, "/data/inputs/fb/census-month/stt/active_population.csv")) %>% 
  rename("name" = "LAD21NM")
  } 
```

```{r}
sum(df_pop_dfd$pop_dfd)
```

# Measure bias

```{r}
df_bias <- df_pop_census %>% left_join(df_pop_dfd, by = "name")
df_bias$bias <- 1 - df_bias$pop_dfd/df_bias$pop
df_bias$map_bias <- (1 - df_bias$pop_dfd/df_bias$pop)*100
```

```{r}
if (dfd == "twitter"){
  write.csv(df_bias, paste0(wd, "/data/outputs/twitter/monthly/populations/active-population-bias/active_population_bias_lad.csv"))
  } else if (dfd == "fb_tts_census_week") {
  write.csv(df_bias, paste0(wd, "/data/outputs/fb/census-week/populations/tts/active-population-bias/active_population_bias_lad.csv"))
  } else if (dfd == "fb_tts_census_montbh") {
  write.csv(df_bias, paste0(wd, "/data/outputs/fb/census-month/populations/tts/active-population-bias/active_population_bias_lad.csv"))
  } else if (dfd == "fb_stt_census_week") {
  write.csv(df_bias, paste0(wd, "/data/outputs/fb/census-week/populations/stt/active-population-bias/active_population_bias_lad.csv"))
  } else if (dfd == "fb_stt_census_month") {
  write.csv(df_bias, paste0(wd, "/data/outputs/fb/census-month/populations/stt/active-population-bias/active_population_bias_lad.csv"))
  }

```

## Scatter plot

```{r}

# Compute the breaks using Jenks natural breaks
if (dfd == "twitter") { 
  num_classes <- 9  # Specify how many breaks you want
} else {
  num_classes <- 8
}

jenks_breaks <- classIntervals(df_bias$bias*100, n = num_classes, style = "jenks")$brks

jenks_breaks <- unique(jenks_breaks)

# Create a factor variable for color breaks
df_bias$jenks_bins <- cut(df_bias$bias*100, breaks = jenks_breaks, include.lowest = TRUE)

# Create a custom color palette from viridis
jenks_colors <- viridis(length(jenks_breaks) - 1)

# Manually format the legend labels to avoid scientific notation
formatted_labels <- sapply(1:(length(jenks_breaks) - 1), function(i) {
  paste0("[", 
         sprintf("%.1f", jenks_breaks[i]), ", ", 
         sprintf("%.1f", jenks_breaks[i + 1]), ")")
})


# Perform the Pearson correlation test, removing NA values
correlation_test <- cor.test(df_bias$pop, df_bias$pop_dfd, use = "complete.obs", method = "pearson")
correlation_coefficient <- round(correlation_test$estimate, 2)
p_value <- correlation_test$p.value
p_annotation <- ifelse(p_value < 0.05, "p < 0.05", paste("p =", round(p_value, 2)))
annotation <- data.frame(
   x = c(max(df_bias$pop*0.88, na.rm = TRUE), 
         max(df_bias$pop*0.88, na.rm = TRUE)),
   y = c(max(df_bias$pop_dfd *0.53, na.rm = TRUE), 
         max(df_bias$pop_dfd *0.4, na.rm = TRUE)),
   label = c(paste0("r = ", correlation_coefficient), p_annotation)
)

# Create the plot
ggplot(df_bias, aes(x = pop, y = pop_dfd, color = jenks_bins)) +
  geom_point(size = 5, alpha = 0.6, stroke = 0.7) +
  scale_color_viridis_d(
    na.translate = TRUE,
    na.value = "gray"  # Color for NA values
  ) +
  labs(
    x = "Population",
    y = "Population DT"
  ) +
  geom_text(data=annotation, aes(x=x, y=y, label=label),
           color="black", 
           size=25, 
           angle=0, 
           fontface="bold",
           family = "robotocondensed") +
  scale_x_continuous(labels = label_number(scale = 0.001, suffix = " k")) +
  scale_y_continuous(labels = label_number(scale = 0.001, suffix = " k")) +
  theme_plot_tufte() +
  theme(axis.title.x = element_text(size = 60),  # Set font size for X-axis title
    axis.title.y = element_text(size = 60),   # Set font size for Y-axis title
    axis.text.x = element_text(size = 50),     # Font size for X-axis ticks
    axis.text.y = element_text(size = 50),
    legend.position = "none",
    plot.margin = unit(c(1, 2, 1, 1), "lines")
    )

if (dfd == "twitter") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/twitter/size-bias/scatter/twitter_lad.png"), bg="white")
  } else if (dfd == "fb_tts_census_week") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/scatter/fb_tts_lad_census_week.png"), bg="white")
  } else if (dfd == "fb_tts_census_month") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/scatter/fb_tts_lad_census_month.png"), bg="white")
  } else if (dfd == "fb_stt_census_week") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/scatter/fb_stt_lad_census_week.png"), bg="white")
  } else if (dfd == "fb_stt_census_month") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/scatter/fb_stt_lad_census_month.png"), bg="white")
  }
```

## Histogram bias

```{r}

# Compute the breaks using Jenks natural breaks
if (dfd == "twitter") { 
  num_classes <- 9  # Specify how many breaks you want
} else {
  num_classes <- 8
}

jenks_breaks <- classIntervals(df_bias$bias*100, n = num_classes, style = "jenks")$brks

# Create a data frame with histogram information
hist_data <- data.frame(value = df_bias$bias*100)

jenks_breaks <- unique(jenks_breaks)

# Create a factor variable for color breaks
hist_data$jenks_bins <- cut(hist_data$value, breaks = jenks_breaks, include.lowest = TRUE)

# Create a custom color palette from viridis
jenks_colors <- viridis(length(jenks_breaks) - 1)

# Manually format the legend labels to avoid scientific notation
formatted_labels <- sapply(1:(length(jenks_breaks) - 1), function(i) {
  paste0("[", 
         sprintf("%.1f", jenks_breaks[i]), ", ", 
         sprintf("%.1f", jenks_breaks[i + 1]), ")")
})

if (dfd == "twitter") { 
  minimum_x <- sort(hist_data$value)[2] - 0.3
  binwidth <- .009
} else {
  minimum_x <- sort(hist_data$value)[1]
  binwidth <- .12
}

# Plot the histogram with ggplot
ggplot(hist_data, aes(x = value, fill = jenks_bins)) +
  xlim(minimum_x, 100) +
  geom_histogram(binwidth=binwidth, color = "black", linewidth = 0.3) +  # Adjust binwidth as needed
  scale_fill_viridis_d(
    name = "Size of bias",
    labels = formatted_labels,
    na.translate = TRUE,
    na.value = "gray"  # Set color for NA values
  ) +
  labs(x = "Size of bias", y = "Frequency") +
  theme_plot_tufte() +
  theme(
    legend.text = element_text(size = 60),       # Increase legend text size
    legend.title = element_text(size = 60),      # Increase legend title size
    legend.position = "right",                     # Optional: adjust legend position
    axis.title.x = element_text(size = 63),  # Set font size for X-axis title
    axis.title.y = element_text(size = 63),   # Set font size for Y-axis title
    axis.text.x = element_text(size = 50),     # Font size for X-axis ticks
    axis.text.y = element_text(size = 50)      # Font size for Y-axis ticks
  )

if (dfd == "twitter") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/twitter/size-bias/histogram/twitter_lad.png"), bg="white")
  } else if (dfd == "fb_tts_census_week") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/histogram/fb_tts_lad_census_week.png"), bg="white")
  } else if (dfd == "fb_tts_census_month") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/histogram/fb_tts_lad_census_month.png"), bg="white")
  } else if (dfd == "fb_stt_census_week") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/histogram/fb_stt_lad_census_week.png"), bg="white")
  } else if (dfd == "fb_stt_census_month") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/histogram/fb_stt_lad_census_month.png"), bg="white")
  }
```

# Spatial autocorrelation

```{r}
st_bias_map <- df_boundaries %>% left_join(df_bias, by = "code") %>% st_as_sf() %>% filter(!grepl("^S", code))
```

## Imputing NA values with their spatial according to queen neighbours

```{r}
# Compute standardised weights matrix based on boundaries for LADs
st_bias_map <- st_bias_map #%>% st_simplify(preserveTopology = TRUE, dTolerance = 100)

nb_q <- poly2nb(st_bias_map, queen = TRUE) 

w_matrix <- nb2listw(nb_q, style = "W", zero.policy = TRUE) 

# Compute spatial lag
bias_w <- lag.listw(w_matrix, st_bias_map$bias, NAOK=TRUE)
map_bias_w <- lag.listw(w_matrix, st_bias_map$map_bias, NAOK=TRUE)

# Find indices where `st_bias_map$bias` is NA
na_indices <- which(is.na(st_bias_map$bias))

# Replace `st_bias_map$bias` at these indices with corresponding values from `bias_w`
st_bias_map$bias[na_indices] <- bias_w[na_indices]
st_bias_map$map_bias[na_indices] <- map_bias_w[na_indices]
```

## Spatial weights matrix

Choose between:

-   `'queen'` (queen neighbourhood)

-   `'fbw'` (fixed band-width, weights as 1/d)

-   `'knn'` (k nearest-neighbours, weights as 1/d)

-   `'db'` (distance band, weights as 1/d)

### Option 1: `queen`

```{r}
if (w_scheme == 'queen'){
  if ("bias_w" %in% colnames(st_bias_map)) {
    st_bias_map <- st_bias_map[, !names(st_bias_map) %in% "bias_w"]
  }
  suffix <- '_w_queen'
  # Compute spatial lag
  bias_w <- lag.listw(w_matrix, st_bias_map$bias, NAOK=TRUE)
  # Save spatial lag in additional column
  st_bias_map$bias_w <- bias_w
}
```


### Option 2: finding optimal fixed band width using `gwr.sel()` function from  `spgwr` package

```{r}

if (w_scheme == 'fbw'){
  if ("bias_w" %in% colnames(st_bias_map)) {
    st_bias_map <- st_bias_map[, !names(st_bias_map) %in% "bias_w"]
  }
  suffix <- '_w_fbw'
  coords <- st_coordinates(st_centroid(st_bias_map))
  # find optimal kernel bandwidth using cross validation
  fbw <- gwr.sel(map_bias ~ 1, 
                 data = st_bias_map, 
                 coords=cbind( coords[, "X"], coords[, "Y"]),
                 longlat = TRUE,
                 adapt = FALSE, 
                 gweight = gwr.Gauss, 
                 verbose = FALSE)
  # Create a distance-based neighbors list with a minimum distance of 0 and maximum distance given by fbw
  nb_d <- dnearneigh(st_coordinates(st_centroid(st_bias_map)), d1=0, d2=fbw)
  # Create a row-standardised spatial weights matrix using distance-based neighbors
  w_matrix <- nb2listw(nb_d, style = "W", zero.policy=TRUE)
  # WARNING!!!!! This weights matrix leaves too many observations disconnected. Below we print the percentage of observations with no neighbors:
  # Find the number of observations with zero neighbors
  zero_neighbors_count <- sum(unlist(lapply(w_matrix$weights, length)) == 0)
  zero_neighbors_count/nrow(st_bias_map)*100
  # Compute spatial lag
  bias_w <- lag.listw(w_matrix, st_bias_map$bias, NAOK=TRUE)
  # Save spatial lag in additional column
  st_bias_map$bias_w <- bias_w
}
```

Too many.

### Option 3: neighbourhoods based on k-nearest neighbours, weights as inverse of distance

```{r}

if (w_scheme == 'knn'){
  if ("bias_w" %in% colnames(st_bias_map)) {
    st_bias_map <- st_bias_map[, !names(st_bias_map) %in% "bias_w"]
  }
  suffix <- '_w_knn'
  # Extract the coordinates of the centroids (or your points)
  coords <- st_coordinates(st_centroid(st_bias_map))
  # Create k-Nearest Neighbors list with k = 10 (using centroids of a spatial object)
  nb_knn <- knearneigh(coords, k = 10)
  # Create weights matrix with equal weights
  w_knn <- knn2nb(nb_knn)
  # Compute distances from observation to neighbours
  k.distances <- nbdists(w_knn, coords)
  # Use these distances as weights
  invd2a <- lapply(k.distances, function(x) (1/(x/100)))
  # Create weights matrix with weights as 1/d, normalised
  w_matrix <- nb2listw(w_knn, glist = invd2a, style = "W")
  # Compute spatial lag
  bias_w <- lag.listw(w_matrix, st_bias_map$bias, NAOK=TRUE)
  # Save spatial lag in additional column
  st_bias_map$bias_w <- bias_w
}  

```

### Option 4: neighbourhoods based on distance band (set by user, unlike fbw which is "optimally" computed), weights as inverse of distance

```{r}

if (w_scheme == 'db'){
  if ("bias_w" %in% colnames(st_bias_map)) {
    st_bias_map <- st_bias_map[, !names(st_bias_map) %in% "bias_w"]
  }
  suffix <- '_w_db'
  # Extract the coordinates of the centroids (or your points)
  coords <- st_coordinates(st_centroid(st_bias_map))
  # Compute distance band to ensure that all the observations have neighbours
  k1 <- knn2nb(knearneigh(coords))
  critical.threshold <- max(unlist(nbdists(k1, coords)))
  # Compute lists of neighbours 
  nb.dist.band <- dnearneigh(coords, 0, critical.threshold)
  # Compute distances
  distances <- nbdists(nb.dist.band, coords)
  # Compute inverse distances
  invd1a <- lapply(distances, function(x) (1/(x/100)))
  # Compute spatial weights matrix, normalised
  w_matrix <- nb2listw(nb.dist.band, glist = invd1a, style = "W", zero.policy=TRUE)
  # Compute spatial lag
  bias_w <- lag.listw(w_matrix, st_bias_map$bias, NAOK=TRUE)
  # Save spatial lag in additional column
  st_bias_map$bias_w <- bias_w
}  
```


### Save data with spatial lag

```{r}
if (dfd == "twitter"){
  write.csv(st_drop_geometry(st_bias_map), 
            paste0(wd, "/data/outputs/twitter/monthly/populations/active-population-bias/active_population_bias_lad", suffix, ".csv"))
} else if (dfd == "fb_tts_census_week") {
  write.csv(st_drop_geometry(st_bias_map), 
            paste0(wd, "/data/outputs/fb/census-week/populations/tts/active-population-bias/active_population_bias_lad", suffix, ".csv"))
} else if (dfd == "fb_tts_census_month") {
  write.csv(st_drop_geometry(st_bias_map), 
            paste0(wd, "/data/outputs/fb/census-month/populations/tts/active-population-bias/active_population_bias_lad", suffix, ".csv"))
} else if (dfd == "fb_stt_census_week") {
  write.csv(st_drop_geometry(st_bias_map), 
            paste0(wd, "/data/outputs/fb/census-week/populations/stt/active-population-bias/active_population_bias_lad", suffix, ".csv"))
} else if (dfd == "fb_stt_census_month") {
  write.csv(st_drop_geometry(st_bias_map), 
            paste0(wd, "/data/outputs/fb/census-month/populations/stt/active-population-bias/active_population_bias_lad", suffix, ".csv"))
}
```


## Moran's I

```{r}
# Moran's I Monte Carlo test
result <- moran.mc(st_bias_map$bias, w_matrix, nsim=1000, alternative="two.sided")

# Extract Moran's I and p-value
mI <- as.numeric(result$statistic)  # Moran's I statistic
p_value_mI <- as.numeric(result$p.value)    # p-value
```

# Map bias

## England and Wales

### Static map

```{r}
# # Replace the specific entry with NA
# # st_bias_map[st_bias_map$code == "E09000001", "map_bias"] <- NA
# 
# # Create a new factor based on Jenks breaks
# st_bias_map$jenks_bins <- cut(st_bias_map$map_bias, jenks_breaks, include.lowest = TRUE)
# 
# 
# ggplot(data = st_bias_map) +
#   geom_sf(aes(fill = jenks_bins)) +
#   scale_fill_viridis_d(name = "Size of bias",
#     labels = formatted_labels,
#     na.translate = TRUE,
#     na.value = "gray") +  # Set color for NA values
#     labs(title = " ") +
#     theme_map_tufte() +
#     theme(
#       legend.text = element_text(size = 60),
#       legend.title = element_text(size = 60),
#       legend.position = "right"
#       )
# 
# if (dfd == "twitter") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/twitter/size-bias/map/twitter_lad.png"), bg="white")
#   } else if (dfd == "fb_tts_census_week") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/map/fb_tts_lad_census_week.png"), bg="white")
#   } else if (dfd == "fb_tts_census_month") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/map/fb_tts_lad_census_month.png"), bg="white")
#   } else if (dfd == "fb_stt_census_week") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/map/fb_stt_lad_census_week.png"), bg="white")
#   } else if (dfd == "fb_stt_census_month") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/map/fb_stt_lad_census_month.png"), bg="white")
#   }
```

### Hexagons

```{r}

st_bias_map <- df_boundaries_hex %>%  filter(!grepl("^S", code))  %>% filter(!grepl("^N", code)) %>% filter(!grepl("^u", code))  %>% left_join(df_bias, by = "code") %>% st_as_sf()

# Replace the specific entry with NA
# st_bias_map[st_bias_map$code == "E09000001", "map_bias"] <- NA

# Create a new factor based on Jenks breaks
st_bias_map$jenks_bins <- cut(st_bias_map$map_bias, jenks_breaks, include.lowest = TRUE)

p_annotation <- ifelse(p_value_mI < 0.05, "p < 0.05", paste("p =", round(p_value_mI, 2)))
bbox <- st_bbox(st_bias_map)  # Get the map's bounding box
xmin <- bbox["xmin"]
xmax <- bbox["xmax"]
ymin <- bbox["ymin"]
ymax <- bbox["ymax"]
annotation <- data.frame(
   x = c(xmin + 0.1*(xmax-xmin), xmin + 0.1*(xmax-xmin)),
   y = c(ymin + 0.85*(ymax-ymin), ymin + 0.75*(ymax-ymin)),
   label = c(paste0("I = ", round(mI,2)), p_annotation)
)

ggplot(data = st_bias_map) +
  geom_sf(aes(fill = jenks_bins)) +
  scale_fill_viridis_d(name = "Size of bias",
    labels = formatted_labels,
    na.translate = FALSE,
    na.value = "gray") +  # Set color for NA values
    labs(title = " ") +
    geom_text(data=annotation, aes(x=x, y=y, label=label),
           color="black",
           size=23,
           angle=0,
           fontface="bold",
           family = "robotocondensed") +
    theme_map_tufte() +
    theme(
      legend.text = element_text(size = 55),
      legend.title = element_text(size = 55),
      legend.position = "right",
      axis.title = element_blank(),        # Remove axis titles
      axis.text = element_blank(),         # Remove axis text
      axis.ticks = element_blank()         # Remove axis ticks
      )

if (dfd == "twitter") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/twitter/size-bias/map/twitter_lad_hex", suffix, ".png"), bg="white") 
  } else if (dfd == "fb_tts_census_week") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/map/fb_tts_lad_census_week_hex", suffix, ".png"), bg="white") 
  } else if (dfd == "fb_tts_census_month") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/map/fb_tts_lad_census_month_hex", suffix, ".png"), bg="white") 
  } else if (dfd == "fb_stt_census_week") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/map/fb_stt_lad_census_week_hex", suffix, ".png"), bg="white") 
  } else if (dfd == "fb_stt_census_month") {
  ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/map/fb_stt_lad_census_month_hex", suffix, ".png"), bg="white") 
  }
```

### Interactive map

```{r}

# st_bias_map <- df_boundaries %>% left_join(df_bias, by = "code") %>% st_as_sf() %>% filter(!grepl("^S", code))
# 
# # Replace the specific entry with NA
# # st_bias_map[st_bias_map$code == "E09000001", "map_bias"] <- NA
# 
# # Create a new factor based on Jenks breaks
# st_bias_map$jenks_bins <- cut(st_bias_map$map_bias, jenks_breaks, include.lowest = TRUE)
# 
# tmap_mode("view") # enable interactivity
# interactive_map <- tm_shape(st_bias_map) + # input data
#     tm_borders() +
#     tm_fill("jenks_bins", # draw and fill polygons
#           palette = "viridis",
#           title = "Size of bias",
#           id="name")
# 
# if (dfd == "twitter"){
#   tmap_save(interactive_map, paste0(wd, "/bias-detection/outputs/preliminary/twitter/size-bias/interactive/twitter_lad.html"))
#   } else if (dfd == "fb_tts_census_week") {
#   tmap_save(interactive, paste0(wd, "/bias-detection/outputs/preliminary/fb_tts/size-bias/interactive/fb_tts_lad_census_week.html"))
#   } else if (dfd == "fb_tts_census_month") {
#   tmap_save(interactive, paste0(wd, "/bias-detection/outputs/preliminary/fb_tts/size-bias/interactive/fb_tts_lad_census_month.html"))
#   } else if (dfd == "fb_stt_census_week") {
#   tmap_save(interactive, paste0(wd, "/bias-detection/outputs/preliminary/fb_stt/size-bias/interactive/fb_stt_lad_census_week.html"))
#   } else if (dfd == "fb_stt_census_month") {
#   tmap_save(interactive, paste0(wd, "/bias-detection/outputs/preliminary/fb_stt/size-bias/interactive/fb_stt_lad_census_month.html"))
#   }
# 
# interactive_map
```

## London

### Static map

```{r}
# 
# st_bias_map <- df_boundaries %>% left_join(df_bias, by = "code") %>% st_as_sf() %>% filter(grepl("^E09", code)) 
# 
# st_bias_map[st_bias_map$code == "E09000001", "map_bias"] <- NA
# 
# st_bias_map$jenks <- cut(st_bias_map$map_bias, breaks$brks, include.lowest = TRUE)
# 
# ggplot(data = st_bias_map) +
#   geom_sf(aes(fill = jenks)) +
#   scale_fill_viridis_d(name = "Size of bias") +  # Adjust color palette
#   labs(title = " ") +
#   theme_map() +
#   theme(
#     legend.text = element_text(size = 24),       # Increase legend text size
#     legend.title = element_text(size = 30),      # Increase legend title size
#     legend.position = "right"                    # Optional: adjust legend position
#   )
# 
# if (dfd == "twitter"){
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/twitter/size-bias/map/twitter_lad_london.png"), bg="white")
#   } else if (dfd == "fb_tts_census_week") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/map/fb_tts_lad_london_census_week.png"), bg="white")
#   } else if (dfd == "fb_tts_census_month") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_tts/size-bias/map/fb_tts_lad_london_census_month.png"), bg="white")
#   } else if (dfd == "fb_stt_census_week") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/map/fb_stt_lad_london_census_week.png"), bg="white")
#   } else if (dfd == "fb_stt_census_month") {
#   ggsave(paste0(wd_local, "/bias-detection/outputs/preliminary/fb_stt/size-bias/map/fb_stt_lad_london_census_month.png"), bg="white")
#   }
```

### Interactive map

```{r}
# tmap_mode("view") # enable interactivity
# interactive_map <- tm_shape(st_bias_map) + # input data
#     tm_borders() +
#     tm_fill("map_bias", # draw and fill polygons
#           palette = "viridis",
#           title = "Size of bias",
#           id="name")
# 
# if (dfd == "twitter"){
#   tmap_save(interactive_map, paste0(wd, "/bias-detection/outputs/preliminary/twitter/size-bias/interactive/twitter_lad_london.html"))
#   } else if (dfd == "fb_tts_census_week") {
#   tmap_save(interactive_map, paste0(wd, "/bias-detection/outputs/preliminary/fb_tts/size-bias/interactive/fb_tts_lad_london_census_week.html"))
#   } else if (dfd == "fb_tts_census_month") {
#   tmap_save(interactive_map, paste0(wd, "/bias-detection/outputs/preliminary/fb_tts/size-bias/interactive/fb_tts_lad_london_census_month.html"))
#   } else if (dfd == "fb_stt_census_week") {
#   tmap_save(interactive_map, paste0(wd, "/bias-detection/outputs/preliminary/fb_stt/size-bias/interactive/fb_stt_lad_london_census_week.html"))
#   } else if (dfd == "fb_stt_census_month") {
#   tmap_save(interactive_map, paste0(wd, "/bias-detection/outputs/preliminary/fb_stt/size-bias/interactive/fb_stt_lad_london_census_month.html"))
#   }
# 
# interactive_map
```
