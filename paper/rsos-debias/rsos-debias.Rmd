---
title: An approach to quantifying the extent of bias in aggregated human population data extracted from digital platforms
author:
  - name: Carmen Cabrera-Arnau
    affiliation: "1"
  - name: Francisco Rowe
    affiliation: "1"
address:
  - code: "1"
    address: Geographic Data Science Lab, Department of Geography and Planning, University of Liverpool, Liverpool, United Kingdom.
  - code: ""
    address: 

corresp_author_name:  "C.Cabrera-Arnau"
corresp_author_email: "C.Cabrera-Arnau@liverpool.ac.uk"

subject:
  - "subject 1"
  - "subject 2"
  - "subject 3"

keywords:
  - one
  - two
  - optional
  - optional
  - optional

abstract: |
  The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here.

## Remove this if not required
ethics: |
  Please provide details on the ethics.
  
data_accessibility: |
  Please provide details on the data availability.

author_contributions: |
  Please provide details of author contributions here.

## Remove this if not required
conflict_of_interest: |
  Please declare any conflict of interest here.

## Remove this if not required
funding: |
  Please provide details on funding

## Remove this if not required
disclaimer: |
  Please provide disclaimer text here.

## Remove this if not required
acknowledgements: |
  Please include your acknowledgments here, set in a single paragraph. Please do not include any acknowledgments in the Supporting Information, or anywhere else in the manuscript.

bibliography: sample.bib

## change to true to add optional line numbering
lineno: false

site: bookdown::bookdown_site
output: 
  bookdown::pdf_book:
    base_format: rticles::rsos_article
---

::: {.callout-note icon="false"}
The main document should include:

Title (no more than 150 characters)

Author names and affiliations, and ORCID iDs where available

Abstract (no more than 200 words). (This will be used in reviewer invitation emails so please think about how to describe your work to make it easy for a potential reviewer to determine whether they would be suitable.)

All main manuscript text. Ensure that all figures, tables and any relevant supplementary materials are mentioned within the text References

Acknowledgements and funding statement (ensure that you have included grant numbers and the names of any funding providers)

Tables with captions Figure captions with credits where relevant
:::

\newpage

# Introduction

<!-- CCA: PROPOSED PARAGRAPH STRUCTURE-->

<!-- P1: The emergence of Digital Footprint Data (DFD) has created new opportunities, particularly for research and policy. -->

<!-- P2: However, DFD is subject to biases that may compromise its representativity. Addressing these biases is critical because, if big data analyses rely on biased data, this can perpetuate social injustice and unfairly amplify socioeconomic disparities. -->

<!-- P3: Biases in DFD can arise from various sources. Here, we focus on biases caused by [specify sources such as demographic gaps, digital divides, or sampling limitations]. -->

<!-- P4: Efforts have been made to measure and explore the nature of biases across multiple data sources (brief literature review). -->

<!-- P5: However, we identify two main gaps. First, there is no standard approach for identifying or correcting biases in spatially and temporally aggregated DFD. Second, little work on the geographic variation of biases. Developing transparent, well-documented standards is essential, especially since most DFD sources are aggregated and, for privacy reasons, do not include user profile information. -->

<!-- P6: This paper aims to establish a framework to address this gap, contributing by proposing a standardised approach for identifying and measuring biases in DFD, as well as explaining the origin of these biases. -->

<!-- THE THREE PARAGRAPHS BELOW WERE WRITTEN BY FR -->

<!--  The rapid growth in mobile phone penetration globally has created new opportunities for research, policy and decision making. Though the collection of call records, data streams, Mobile phones record highly precise and frequent location information in real time. As such, -->

<!-- Location data extracted from mobile phones represent a great resource to understand the spatio-temporal patterns of human mobility; that is, how and where people move. However, differences in the access and use of digital technology, such as smartphone applications across the population create biases leading to variations in the statistical representation of population groups in the resulting datasets. These biases have represented a major obstacle, leading to skepticism and deterring widespread use of these data. Work has made some progress on addressing biases for data capturing basic population attributes, such as sex and age. Less has been done at addressing biases for data which do not disclose population attributes. This paper provides a general overview of existing biases and state-of-the-art approaches, and discusses potential avenues for future research. -->

<!-- Focus on aggregated data to ensure privacy and confidentiality -->

<!-- CCA: I COPIED THE TEXT BELOW FROM CFS AS IT GATHERS MANY OF THE POINTS WE WANT TO MAKE IN THE INTRODUCTION AS WELL AS MULTIPLE REFERENCES -->

Location data derived from DFs collected via digital technology, has created new opportunities for research, policy and decision making. These data offer high geographic and temporal granularity, extensive coverage and instant information to measure and transform our understanding of human mobility [@oliver20-health]. DF data (DFD) generation expands countries facilitating comparative analyses. Substantively, studies leveraging DFD have contributed to expanding existing theories, developing new explanations, adopting new analytical tools and infrastructures, and advancing new areas of research, such as computational social science and geographic data science [@pappalardo23-directions]. Yet, these data also present major epistemological, methodological and ethical challenges [@rowe23-bigdata].

A key unresolved limitation in the use of DFD is the potential presence of biases relating to its statistical representativeness. Two sources of biases are particularly prominent. First, biases emerge from differences in the access and use of the particular digital technology, such as mobile applications, used to collect data [@wesolowski13-biases]. In the UK, for example, we know that 98% of the adult population have a mobile phone and 92% of this population use a smartphone [@ofcom23], but a smaller percentage actively use Facebook (70%) or Twitter (23%) [@statista24]. Second, biases can also emerge from differences in the access and usage of digital technologies across population groups. DF-derived mobility data from Twitter, for instance, display a young adult, male and urban user profile (e.g. [@mislove21-twitter], [@sloan13-twitter]). Differences in age, income and education have been found in Facebook-derived population counts [@ribeiro20-facebook]. As a result, DF-derived mobility data cannot be interpreted directly to provide a reliable estimate of population mobility levels [@cesare18-promises]. They can only afford to offer rough signals about mobility patterns (e.g. spatial concentration), trends (e.g. increasing) and changes (e.g. low to high) [@rowe22-sensing-ukraine].

Efforts have been made to correct these biases through two general approaches. A first general approach consists in adjusting DF-derived population counts from social media by developing correction factors (e.g. [@yildiz17-twitter], [@Hsiao24-bias]). Correction factors are often estimated as the ratio of active social media users to census population counts by demographic attributes (e.g. age). The principles are similar to survey post-stratification methods i.e. to make DF-derived population counts representative of the census populations. However, a key data requirement of this approach is on having data on population by attribute, but such data are generally unavailable from DFs. Only information on location, time and total active users is recorded. As such, this approach cannot be generalised to different DFD sources and geographical contexts, and when applied on total population counts, biases associated with demographic and socioeconomic user attributes are not corrected (e.g. [@rodriguez-carrion18-biases], [@schlosser21-biases], [@pak22-correcting-bias]). A second approach uses a regression modelling approach. Intuitively this approach produces representative population counts by explicitly measuring and removing the sources of biases in the data [@kramer-schadt13-bias-correction]. This approach has primarily been used in Ecology to obtain representative population distributions of animal species [@zizka21-sampbias], but it has not been used in the context of DFD. In recent work, the PI adopted a similar approach to correct multiple sources of biases in census data to produce bias-adjusted migration estimates [@aparicio-castro23-bayesian]. DEBIAS builds on this work to develop a general framework and software package aiming to correct biases in origin-destination mobility counts derived from DFs in the absence of demographic and socioeconomic information on users of digital platforms.

# Data and methods

## Data

### Facebook

### Twitter

### Other

## Methods

In this section, we present our proposed methodology, which has two primary aims: first, to quantify biases, and second, to identify the characteristics of local populations that increase their likelihood of being underrepresented in digital footprint data (DFD). This methodology serves as a general framework applicable to any digital technology that captures active user counts and operates on data aggregated into spatial and temporal units, aligning well with the structure of many DFD sources available to researchers.

The methodology unfolds in two interconnected stages, each corresponding to our aims. In the first stage, we develop a statistical indicator to quantify the magnitude of bias in each subnational area. This step is crucial for establishing a baseline understanding of bias levels, allowing us to pinpoint regions with significant underrepresentation. In the second stage, we analyse the association of these biases with demographic, socioeconomic, and geographic attributes at the area level. This analysis yields insights into the underlying characteristics contributing to disparities in the level of bias across areas, thereby addressing our second methodological aim.

### Measuring bias

We define a metric to quantify the magnitude of bias in each subnational area. We do this by estimating the extent of population coverage of the digital technology used to collect the DFD (e.g. Facebook app). This is computed as the ratio of the user population of the digital technology ($P_i^D$) to the total local population of an area ($P_i$). Formally, the coverage $c_i$ is given by:
\begin{equation}
c_i = \dfrac{P_i^D}{P_i} \times 100,
\end{equation}
where $D$ identifies a given digital technology, and $i$ denotes each subnational area. The ratio is assumed to take values between $0$ and $100$, with the latter representing full population coverage. The ratio can only take values greater than $1$ if users have multiple accounts exceeding the total local population of an area. 

We then define the size of bias $e_i$ as:
\begin{equation}
e_i = 100 - c_i
\end{equation}
in which case, $e_i = 0$ will indicate full population coverage or no bias. We will use this indicator to examine the magnitude and spatial distribution of bias in multiple sources of digital trace data.


### Assessing the driving factors of bias

We seek to understand the association between the size of bias and area-level
demographic and socioeconomic attributes. To what extent different demographic and socioeconomic
groups are represented in DFD? And how do these vary geographically and across digital platform?
We will assess these questions by measuring the area-level association between our coverage
indicator and key demographic and socioeconomic attributes. We will use a random forest to model
our coverage indicator as a function of demographic and socioeconomic attributes. The outcomes will
identify the most important area-level demographic and socioeconomic features to predict the
coverage bias of a given digital technology. We will use this information to inform our models in WP-II.

eXtreme Gradient Boosting (XGBoost) is an efficient and scalable implementation of gradient boosting framework by [@friedman2001; @friedman2000].

# Results

## Measuring the extent of biases

## Assessing the extent of biases in digital trace data

## Explaining biases

# Discussion

# Conclusion

# References
