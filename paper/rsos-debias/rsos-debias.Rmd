---
title: An approach to quantifying the extent of bias in aggregated human population data extracted from digital platforms
author:
  - name: Carmen Cabrera-Arnau
    affiliation: "1"
  - name: Francisco Rowe
    affiliation: "1"
address:
  - code: "1"
    address: Geographic Data Science Lab, Department of Geography and Planning, University of Liverpool, Liverpool, United Kingdom.
  - code: ""
    address: 

corresp_author_name:  "C. Cabrera-Arnau"
corresp_author_email: "C.Cabrera-Arnau@liverpool.ac.uk"

subject:
  - "subject 1"
  - "subject 2"
  - "subject 3"

keywords:
  - one
  - two
  - optional
  - optional
  - optional

abstract: |
  The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here.

## Remove this if not required
ethics: |
  Please provide details on the ethics.
  
data_accessibility: |
  Please provide details on the data availability.

author_contributions: |
  Please provide details of author contributions here.

## Remove this if not required
conflict_of_interest: |
  Please declare any conflict of interest here.

## Remove this if not required
funding: |
  Please provide details on funding

## Remove this if not required
disclaimer: |
  Please provide disclaimer text here.

## Remove this if not required
acknowledgements: |
  Please include your acknowledgments here, set in a single paragraph. Please do not include any acknowledgments in the Supporting Information, or anywhere else in the manuscript.

bibliography: sample.bib

## change to true to add optional line numbering
lineno: false

site: bookdown::bookdown_site
output: 
  bookdown::pdf_book:
    base_format: rticles::rsos_article
---

::: {.callout-note icon="false"}
The main document should include:

Title (no more than 150 characters)

Author names and affiliations, and ORCID iDs where available

Abstract (no more than 200 words). (This will be used in reviewer invitation emails so please think about how to describe your work to make it easy for a potential reviewer to determine whether they would be suitable.)

All main manuscript text. Ensure that all figures, tables and any relevant supplementary materials are mentioned within the text References

Acknowledgements and funding statement (ensure that you have included grant numbers and the names of any funding providers)

Tables with captions Figure captions with credits where relevant
:::

\newpage

# Introduction

<!-- CCA: PROPOSED PARAGRAPH STRUCTURE-->

<!-- P1: The emergence of Digital Footprint Data (DFD) has created new opportunities, particularly for research and policy. -->

<!-- P2: However, DFD is subject to biases that may compromise its representativity. Addressing these biases is critical because, if big data analyses rely on biased data, this can perpetuate social injustice and unfairly amplify socioeconomic disparities. -->

<!-- P3: Biases in DFD can arise from various sources. Here, we focus on biases caused by [specify sources such as demographic gaps, digital divides, or sampling limitations]. -->

<!-- P4: Efforts have been made to measure and explore the nature of biases across multiple data sources (brief literature review). -->

<!-- P5: However, there is no standard approach for identifying or correcting biases in spatially and temporally aggregated DFD. Developing transparent, well-documented standards is essential, especially since most DFD sources are aggregated and, for privacy reasons, do not include user profile information. -->

<!-- P6: This paper aims to establish a framework to address this gap, contributing by proposing a standardised approach for identifying and measuring biases in DFD, as well as explaining the origin of these biases. -->

<!-- THE THREE PARAGRAPHS BELOW WERE WRITTEN BY FR -->

<!--  The rapid growth in mobile phone penetration globally has created new opportunities for research, policy and decision making. Though the collection of call records, data streams, Mobile phones record highly precise and frequent location information in real time. As such, -->

<!-- Location data extracted from mobile phones represent a great resource to understand the spatio-temporal patterns of human mobility; that is, how and where people move. However, differences in the access and use of digital technology, such as smartphone applications across the population create biases leading to variations in the statistical representation of population groups in the resulting datasets. These biases have represented a major obstacle, leading to skepticism and deterring widespread use of these data. Work has made some progress on addressing biases for data capturing basic population attributes, such as sex and age. Less has been done at addressing biases for data which do not disclose population attributes. This paper provides a general overview of existing biases and state-of-the-art approaches, and discusses potential avenues for future research. -->

<!-- Focus on aggregated data to ensure privacy and confidentiality -->

<!-- CCA: I COPIED THE TEXT BELOW FROM CFS AS IT GATHERS MANY OF THE POINTS WE WANT TO MAKE IN THE INTRODUCTION AS WELL AS MULTIPLE REFERENCES -->

Location data derived from DFs collected via digital technology, has created new opportunities for research, policy and decision making. These data offer high geographic and temporal granularity, extensive coverage and instant information to measure and transform our understanding of human mobility [@oliver20-health]. DF data (DFD) generation expands countries facilitating comparative analyses. Substantively, studies leveraging DFD have contributed to expanding existing theories, developing new explanations, adopting new analytical tools and infrastructures, and advancing new areas of research, such as computational social science and geographic data science [@pappalardo23-directions]. Yet, these data also present major epistemological, methodological and ethical challenges [@rowe23-bigdata].

A key unresolved limitation in the use of DFD is the potential presence of biases relating to its statistical representativeness. Two sources of biases are particularly prominent. First, biases emerge from differences in the access and use of the particular digital technology, such as mobile applications, used to collect data [@wesolowski13-biases]. In the UK, for example, we know that 98% of the adult population have a mobile phone and 92% of this population use a smartphone [@ofcom23], but a smaller percentage actively use Facebook (70%) or Twitter (23%) [@statista24]. Second, biases can also emerge from differences in the access and usage of digital technologies across population groups. DF-derived mobility data from Twitter, for instance, display a young adult, male and urban user profile (e.g. [@mislove21-twitter], [@sloan13-twitter]). Differences in age, income and education have been found in Facebook-derived population counts [@ribeiro20-facebook]. As a result, DF-derived mobility data cannot be interpreted directly to provide a reliable estimate of population mobility levels [@cesare18-promises]. They can only afford to offer rough signals about mobility patterns (e.g. spatial concentration), trends (e.g. increasing) and changes (e.g. low to high) [@rowe22-sensing-ukraine].

Efforts have been made to correct these biases through two general approaches. A first general approach consists in adjusting DF-derived population counts from social media by developing correction factors (e.g. [@yildiz17-twitter], [@Hsiao24-bias]). Correction factors are often estimated as the ratio of active social media users to census population counts by demographic attributes (e.g. age). The principles are similar to survey post-stratification methods i.e. to make DF-derived population counts representative of the census populations. However, a key data requirement of this approach is on having data on population by attribute, but such data are generally unavailable from DFs. Only information on location, time and total active users is recorded. As such, this approach cannot be generalised to different DFD sources and geographical contexts, and when applied on total population counts, biases associated with demographic and socioeconomic user attributes are not corrected (e.g. [@rodriguez-carrion18-biases], [@schlosser21-biases], [@pak22-correcting-bias]). A second approach uses a regression modelling approach. Intuitively this approach produces representative population counts by explicitly measuring and removing the sources of biases in the data [@kramer-schadt13-bias-correction]. This approach has primarily been used in Ecology to obtain representative population distributions of animal species [@zizka21-sampbias], but it has not been used in the context of DFD. In recent work, the PI adopted a similar approach to correct multiple sources of biases in census data to produce bias-adjusted migration estimates [@aparicio-castro23-bayesian]. DEBIAS builds on this work to develop a general framework and software package aiming to correct biases in origin-destination mobility counts derived from DFs in the absence of demographic and socioeconomic information on users of digital platforms.

# Data and methods

## Data

Facebook

Twitter

## Methods

### Bias indicator

### Effective sample size

### Machine learning

eXtreme Gradient Boosting (XGBoost) is an efficient and scalable implementation of gradient boosting framework by [@friedman2001; @friedman2000].

# Results

## Measuring the extent of biases

## Assessing the extent of biases in digital trace data

## Explaining biases

# Discussion

# Conclusion

# References
