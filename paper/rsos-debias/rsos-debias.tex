%% Author_tex.tex
%% V1.0
%% 2012/13/12
%% developed by Techset
%%
%% This file describes the coding for rsproca.cls

\documentclass[]{rsos}%%%%where rsos is the template name


\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}


% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% From pandoc table feature
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}



%%%% *** Do not adjust lengths that control margins, column widths, etc. ***

%%%%%%%%%%% Defining Enunciations  %%%%%%%%%%%
\newtheorem{theorem}{\bf Theorem}[section]
\newtheorem{condition}{\bf Condition}[section]
\newtheorem{corollary}{\bf Corollary}[section]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}


%%%% Article title to be placed here
\title{An approach to quantifying the extent of bias in aggregated human population data extracted from digital platforms}

\author{
Carmen Cabrera-Arnau$^{1}$,
Francisco Rowe$^{1}$}

\address{
  $^{1}$Geographic Data Science Lab, Department of Geography and Planning, University of Liverpool, Liverpool, United Kingdom.\\
  $^{}$}
%%%% Subject entries to be placed here %%%%
\subject{
subject 1,
subject 2,
subject 3}

%%%% Keyword entries to be placed here %%%%
\keywords{
one,
two,
optional,
optional,
optional}

%%%% Insert corresponding author and its email address}
\corres{
  C.Cabrera-Arnau\\
  e-mail: \href{mailto:C.Cabrera-Arnau@liverpool.ac.uk}{\nolinkurl{C.Cabrera-Arnau@liverpool.ac.uk}}
}

%%%% Abstract text to be placed here %%%%%%%%%%%%
\begin{abstract}
The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\providecommand{\EndFirstPage}{%
}

\maketitle

The main document should include:

Title (no more than 150 characters)

Author names and affiliations, and ORCID iDs where available

Abstract (no more than 200 words). (This will be used in reviewer invitation emails so please think about how to describe your work to make it easy for a potential reviewer to determine whether they would be suitable.)

All main manuscript text. Ensure that all figures, tables and any relevant supplementary materials are mentioned within the text References

Acknowledgements and funding statement (ensure that you have included grant numbers and the names of any funding providers)

Tables with captions Figure captions with credits where relevant

\newpage

\section{Introduction}\label{introduction}

Location data derived from DFs collected via digital technology, has created new opportunities for research, policy and decision making. These data offer high geographic and temporal granularity, extensive coverage and instant information to measure and transform our understanding of human mobility \citep{oliver20-health}. DF data (DFD) generation expands countries facilitating comparative analyses. Substantively, studies leveraging DFD have contributed to expanding existing theories, developing new explanations, adopting new analytical tools and infrastructures, and advancing new areas of research, such as computational social science and geographic data science \citep{pappalardo23-directions}. Yet, these data also present major epistemological, methodological and ethical challenges \citep{rowe23-bigdata}.

A key unresolved limitation in the use of DFD is the potential presence of biases relating to its statistical representativeness. Two sources of biases are particularly prominent. First, biases emerge from differences in the access and use of the particular digital technology, such as mobile applications, used to collect data \citep{wesolowski13-biases}. In the UK, for example, we know that 98\% of the adult population have a mobile phone and 92\% of this population use a smartphone \citep{ofcom23}, but a smaller percentage actively use Facebook (70\%) or Twitter (23\%) \citep{statista24}. Second, biases can also emerge from differences in the access and usage of digital technologies across population groups. DF-derived mobility data from Twitter, for instance, display a young adult, male and urban user profile (e.g. \citep{mislove21-twitter}, \citep{sloan13-twitter}). Differences in age, income and education have been found in Facebook-derived population counts \citep{ribeiro20-facebook}. As a result, DF-derived mobility data cannot be interpreted directly to provide a reliable estimate of population mobility levels \citep{cesare18-promises}. They can only afford to offer rough signals about mobility patterns (e.g.~spatial concentration), trends (e.g.~increasing) and changes (e.g.~low to high) \citep{rowe22-sensing-ukraine}.

Efforts have been made to correct these biases through two general approaches. A first general approach consists in adjusting DF-derived population counts from social media by developing correction factors (e.g. \citep{yildiz17-twitter}, \citep{Hsiao24-bias}). Correction factors are often estimated as the ratio of active social media users to census population counts by demographic attributes (e.g.~age). The principles are similar to survey post-stratification methods i.e.~to make DF-derived population counts representative of the census populations. However, a key data requirement of this approach is on having data on population by attribute, but such data are generally unavailable from DFs. Only information on location, time and total active users is recorded. As such, this approach cannot be generalised to different DFD sources and geographical contexts, and when applied on total population counts, biases associated with demographic and socioeconomic user attributes are not corrected (e.g. \citep{rodriguez-carrion18-biases}, \citep{schlosser21-biases}, \citep{pak22-correcting-bias}). A second approach uses a regression modelling approach. Intuitively this approach produces representative population counts by explicitly measuring and removing the sources of biases in the data \citep{kramer-schadt13-bias-correction}. This approach has primarily been used in Ecology to obtain representative population distributions of animal species \citep{zizka21-sampbias}, but it has not been used in the context of DFD. In recent work, the PI adopted a similar approach to correct multiple sources of biases in census data to produce bias-adjusted migration estimates \citep{aparicio-castro23-bayesian}. DEBIAS builds on this work to develop a general framework and software package aiming to correct biases in origin-destination mobility counts derived from DFs in the absence of demographic and socioeconomic information on users of digital platforms.

\section{Data and methods}\label{data-and-methods}

\subsection{Data}\label{data}

Facebook

Twitter

\subsection{Methods}\label{methods}

In this section, we present our proposed methodology, which has two primary aims: first, to quantify biases, and second, to identify the characteristics of local populations that increase their likelihood of being underrepresented in digital footprint data (DFD). This methodology serves as a general framework applicable to any digital technology that captures active user counts and operates on data aggregated into spatial and temporal units, aligning well with the structure of many DFD sources available to researchers.

The methodology unfolds in two interconnected stages, each corresponding to our aims. In the first stage, we develop a statistical indicator to quantify the magnitude of bias in each subnational area. This step is crucial for establishing a baseline understanding of bias levels, allowing us to pinpoint regions with significant underrepresentation. In the second stage, we analyse the association of these biases with demographic, socioeconomic, and geographic attributes at the area level. This analysis yields insights into the underlying characteristics contributing to disparities in the level of bias across areas, thereby addressing our second methodological aim.

\subsubsection{Bias indicator}\label{bias-indicator}

First, we define a metric to quantify the magnitude of bias in each subnational area. We will do this by estimating the extent of population coverage of the digital technology used to collect the DFD (e.g.~Facebook app). This will be computed as the ratio of the user population of the digital technology (\(P_i^D\)) to the total local population of an area (\(P_i\)). Formally, the coverage \(c_i\) is given by:
\begin{equation}
c_i = \dfrac{P_i^D}{P_i},
\end{equation}
where \(ùê∑\) identifies a given digital technology, and \(i\) denotes each subnational area. The
ratio is assumed to take values between \(0\) and \(1\), with the latter representing full population coverage.
The ratio can only take values greater than \(1\) if users have multiple accounts exceeding the total local
population of an area.

We then define the size of bias \(e_i\) as:
\begin{equation}
e_i = 1 - c_i
\end{equation}
in which case, \(e_i = 0\) will indicate full population coverage or no bias. We will use this indicator to examine the magnitude and spatial distribution of DFD bias.

\subsubsection{Machine learning}\label{machine-learning}

Second, we will seek to understand how DF coverage biases are associated with area-level
demographic and socioeconomic attributes. To what extent different demographic and socioeconomic
groups are represented in DFD? And how do these vary geographically and across digital platform?
We will assess these questions by measuring the area-level association between our coverage
indicator and key demographic and socioeconomic attributes. We will use a random forest to model
our coverage indicator as a function of demographic and socioeconomic attributes. The outcomes will
identify the most important area-level demographic and socioeconomic features to predict the
coverage bias of a given digital technology. We will use this information to inform our models in WP-II.

eXtreme Gradient Boosting (XGBoost) is an efficient and scalable implementation of gradient boosting framework by \citep{friedman2001, friedman2000}.

\section{Results}\label{results}

\subsection{Measuring the extent of biases}\label{measuring-the-extent-of-biases}

\subsection{Assessing the extent of biases in digital trace data}\label{assessing-the-extent-of-biases-in-digital-trace-data}

\subsection{Explaining biases}\label{explaining-biases}

\section{Discussion}\label{discussion}

\section{Conclusion}\label{conclusion}

\ethics{Please provide details on the ethics.}

\dataccess{Please provide details on the data availability.}

\aucontribute{Please provide details of author contributions here.}

\competing{Please declare any conflict of interest here.}

\funding{Please provide details on funding}

\disclaimer{Please provide disclaimer text here.}

\ack{Please include your acknowledgments here, set in a single paragraph. Please do not include any acknowledgments in the Supporting Information, or anywhere else in the manuscript.}

\bibliographystyle{RS}
\bibliography{sample.bib}


\end{document}
