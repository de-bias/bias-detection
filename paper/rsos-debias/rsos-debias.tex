%% Author_tex.tex
%% V1.0
%% 2012/13/12
%% developed by Techset
%%
%% This file describes the coding for rsproca.cls

\documentclass[]{rsos}%%%%where rsos is the template name


\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}


% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% From pandoc table feature
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}



%%%% *** Do not adjust lengths that control margins, column widths, etc. ***

%%%%%%%%%%% Defining Enunciations  %%%%%%%%%%%
\newtheorem{theorem}{\bf Theorem}[section]
\newtheorem{condition}{\bf Condition}[section]
\newtheorem{corollary}{\bf Corollary}[section]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}


%%%% Article title to be placed here
\title{An approach to quantifying the extent of bias in aggregated human population data extracted from digital platforms}

\author{
Carmen Cabrera-Arnau$^{1}$,
Francisco Rowe$^{1}$}

\address{
  $^{1}$Geographic Data Science Lab, Department of Geography and Planning, University of Liverpool, Liverpool, United Kingdom.\\
  $^{}$}
%%%% Subject entries to be placed here %%%%
\subject{
subject 1,
subject 2,
subject 3}

%%%% Keyword entries to be placed here %%%%
\keywords{
one,
two,
optional,
optional,
optional}

%%%% Insert corresponding author and its email address}
\corres{
  C. Cabrera-Arnau\\
  e-mail: \href{mailto:C.Cabrera-Arnau@liverpool.ac.uk}{\nolinkurl{C.Cabrera-Arnau@liverpool.ac.uk}}
}

%%%% Abstract text to be placed here %%%%%%%%%%%%
\begin{abstract}
The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here. The abstract text goes here.
\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\providecommand{\EndFirstPage}{%
}

\maketitle

The main document should include:

Title (no more than 150 characters)

Author names and affiliations, and ORCID iDs where available

Abstract (no more than 200 words). (This will be used in reviewer invitation emails so please think about how to describe your work to make it easy for a potential reviewer to determine whether they would be suitable.)

All main manuscript text. Ensure that all figures, tables and any relevant supplementary materials are mentioned within the text References

Acknowledgements and funding statement (ensure that you have included grant numbers and the names of any funding providers)

Tables with captions Figure captions with credits where relevant

\newpage

\section{Introduction}\label{introduction}

% Focus on aggregated data to ensure privacy and confidentiality

% Aim: To propose a methodological framework to measure biases in human population data from digital platforms.

% Contributions:

Location data derived from DFs collected via digital technology, such as mobile apps have emerged
as a novel source to capture human mobility flows. These data offer high geographic and temporal
granularity, extensive coverage and instant information to measure and transform our understanding
of human mobility \cite{oliver20-health}. DF data (DFD) generation expands countries facilitating
comparative analyses. Substantively, studies leveraging DFD have contributed to expanding existing
theories, developing new explanations, adopting new analytical tools and infrastructures, and
advancing new areas of research, such as computational social science and geographic data science
\cite{pappalardo23-directions}. Yet, these data also present major epistemological, methodological and ethical challenges \cite{rowe23-bigdata}.

A key unresolved limitation in the use of DFD is the potential presence of biases relating to its
statistical representativeness. Two sources of biases are particularly prominent. First, biases emerge from differences in the access and use of the particular digital technology, such as mobile
applications, used to collect data \cite{wesolowski13-biases}. In the UK, for example, we know that 98\% of the adult population have a mobile phone and 92\% of this population use a smartphone \cite{ofcom23}, but a smaller percentage actively use Facebook (70\%) or Twitter (23\%) \cite{statista24}. Second, biases can also emerge from differences in the access and usage of digital technologies across population groups. DF-derived mobility data from Twitter, for instance, display a young adult, male and urban user profile (e.g. \cite{mislove21-twitter}, \cite{sloan13-twitter}). Differences in age, income and education have been found in Facebook-derived population counts \cite{ribeiro20-facebook}. As a result, DF-derived mobility data cannot be interpreted directly to provide a reliable estimate of population mobility levels \cite{cesare18-promises}. They can only afford to offer rough signals about mobility patterns (e.g. spatial concentration), trends (e.g. increasing) and changes (e.g. low to high)
\cite{rowe22-sensing-ukraine}.

Efforts have been made to correct these biases through two general approaches. A first general
approach consists in adjusting DF-derived population counts from social media by developing
correction factors (e.g. \cite{yildiz17-twitter}, \cite{hsiao24-bias}). Correction factors are often estimated as the ratio of active social media users to census population counts by demographic attributes (e.g. age). The principles are similar to survey post-stratification methods i.e. to make DF-derived population counts representative of the census populations. However, a key data requirement of this approach is on having data on population by attribute, but such data are generally unavailable from DFs. Only information on location, time and total active users is recorded. As such, this approach cannot be generalised to different DFD sources and geographical contexts, and when applied on total population counts, biases associated with demographic and socioeconomic user attributes are not corrected (e.g. \cite{rodriguez-carrion18-biases}, \cite{schlosser21-biases}, \cite{pak22-correcting-bias}). A second approach uses a regression modelling approach. Intuitively this approach produces representative population counts by explicitly measuring and removing the sources of biases in the data \cite{kramer-schadt13-bias-correction}. This approach has primarily been used in Ecology to obtain representative population distributions of animal species \cite{zizka21-sampbias}, but it has not been used in the context of DFD. In recent work, the PI adopted a similar approach to correct multiple sources of biases in census data to produce bias-adjusted migration estimates \cite{aparicio-castro23-bayesian}. DEBIAS builds on this work to develop a general framework and software package aiming to correct biases in origin-destination mobility counts derived from DFs in the absence of demographic and socioeconomic information on users of digital platforms.

\section{Data and methods}\label{data-and-methods}

\subsection{Data}\label{data}

Facebook

Twitter

\subsection{Methods}\label{methods}

\subsubsection{Bias indicator}\label{bias-indicator}

\subsubsection{Effective sample size}\label{effective-sample-size}

\subsubsection{Machine learning}\label{machine-learning}

\section{Results}\label{results}

\subsection{Measuring the extent of biases}\label{measuring-the-extent-of-biases}

\subsection{Assessing the extent of biases in digital trace data}\label{assessing-the-extent-of-biases-in-digital-trace-data}

\subsection{Explaining biases}\label{explaining-biases}

\section{Discussion}\label{discussion}

\section{Conclusion}\label{conclusion}

\ethics{Please provide details on the ethics.}

\dataccess{Please provide details on the data availability.}

\aucontribute{Please provide details of author contributions here.}

\competing{Please declare any conflict of interest here.}

\funding{Please provide details on funding}

\disclaimer{Please provide disclaimer text here.}

\ack{Please include your acknowledgments here, set in a single paragraph. Please do not include any acknowledgments in the Supporting Information, or anywhere else in the manuscript.}

\bibliographystyle{RS}
\bibliography{sample.bib}


\end{document}
